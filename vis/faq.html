<!DOCTYPE html>

<html lang="en">
<head>
	<title>Voting with your tweet FAQ</title>
	
	<link rel="stylesheet" href="styles/vt_main.css" type="text/css" />

	<!--[if IE]>
		<script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

	<!--[if lte IE 7]>
		<link rel="stylesheet" type="text/css" media="all" href="css/ie.css"/>
		<script src="js/IE8.js" type="text/javascript"></script><![endif]-->

	<!--[if lt IE 7]>
		<link rel="stylesheet" type="text/css" media="all" href="css/ie6.css"/><![endif]-->
	
</head>

<body id="index" class="home">
	
	<header id="banner" class="body">
			<h1><a href="index.html">Voting with your tweet<br /><strong>This is text introducing the page. It will be easier to write once the viz is finished.</strong></a></h1>
			<nav><ul>
				<li><a href="index.html">Prediction</a></li>
				<li><a href="#">Map</a></li>
				<li class="active"><a href="#">FAQ</a></li>
				<li><a href="#">Data</a></li>
			</ul></nav>
		</header><!-- /#banner -->

<section id="content" class="body">
  <div id="vt_faq_overview">
    <p><span style="padding-right:10px;">Content:</span><span style="padding-right:10px;"><a href="#vt_faq_data">Data and Sources</a></span><span style="padding-right:10px;"><a href="#vt_faq_algorithm">Algorithms</a></span><span style="padding-right:10px;"><a href="#faq_vt_topic_models">Topic Models</a></span><span style="padding-right:10px;"><a href="#faq_vt_other">Other</a></span></p>
    

	
    <h2><a name="intro">Introduction</a></h2>
    <ol>
      <li>What is Voting with your tweet trying to
      do</li>
      <p class="vt_answer">This is first and foremost
      an <i>experiment</i> in trying to see how well we can use
      social media to generate election predictions across
      cycles. The FAQ below covers many of the aspects of how we are
      doing this, why it might work, and why it could fail completely.</p>
      

    <li>How do you predict who will win in each district?</li>
    <p class="vt_answer"> We mine the Twitter data feed each night for tweets that mentioned
    each Congressional candidate in the prior 24 hours. We add those
    mentions to all mentions of each candidate in our database. We
    then feed that text into an algorithm that generates the
    prediction.</p>

    <p class="vt_answer">If you want more information see the FAQs about the data and
    algorithm below. If you want way more information, you can read the
    interim technical
    report <a href="http://markhuberty.berkeley.edu/files/twitter_paper.pdf">here</a>. </p>
    
    <li>This seems dubious. Should I trust your predictions?</li>
    <p class="vt_answer"><b> Probably not!</b> Voting with your Tweet is an experiment. We
    think this might work (we even think we might know
    exactly why it will work). But we could fail spectacularly!</p>

    <li>If I shouldn't trust the predictions, then why are you doing
    this?</li>
    <p class="vt_answer">As we said in the beginning, this is mostly an experiment. Lots of
    papers have tried to predict elections after the fact. Doing this
    publicly is as much a commitment mechanism for us as anything else.</p>

    <li> Who else is doing this kind of thing?</li>

    <p class="vt_answer">Predicting elections with Twitter is a
    popular thing to do. See these papers if you are interested:</p>
    <ul class="vt_answer">
      
      <li><a href="http://www.aaai.org/ocs/index.php/ICWSM/ICWSM10/paper/viewPDFInterstitial/1536/1842">O'Connor, Balasubramanyan, Routledge, and Smith</a>. From Tweets to polls: Linking text sentiment to public opinion time series. In <i>Proceedings of the International AAAI Conference on Weblogs and Social Media</i>, pages 122â€“129, 2010.</li>
      <li><a href="http://www.aaai.org/ocs/index.php/ICWSM/ICWSM10/paper/viewFile/1441/1852">Tumasjan, A. et al</a>. Election Forecasts With Twitter: How 140
      Characters Reflect the Political Landscape. <i>Social Science
      Computer Review</i>. 2010.</li>
      <li><a href="http://www.scribd.com/doc/31208748/Tweetminster-Predicts-Findings">Tweetminster</a>. Is word of mouth correlated to General
      Election results? The results are in. 2010.</li>    
    </ul>
    
    <p class="vt_answer">Additionally, Twitter itself is running a <a href="">Presidential election
    sentiment index</a>.</p>

    <li>Should I trust them?</li>
    <p class="vt_answer">Maybe, maybe not. These papers are all very
    smart. But as Daniel Gayo-Avello of the University of Oviedo (Spain) has <a href="http://arxiv.org/abs/1204.6441">pointed</a> <a href="http://arxiv.org/pdf/1206.5851.pdf">out</a>, 
    most of these papers (and <a href="http://markhuberty.berkeley.edu/files/twitter_paper.pdf.zip">Mark's technical report</a>)
    were <i>retrospective</i>. They looked at elections after they'd
    already happened, rather than trying to predict elections before
    the fact. To test whether their predictors worked, they held back
    some of the election results from the data they used to train
    their predictors. They could then test the accuracy of the
    algorithm on this data, which the algorithm hadn't seen
    before. 

    <p class="vt_answer">But because so much can change between elections, that's
    not quite the same thing as trying to predict the outcomes of an
    entirely new election. For instance, an algorithm built on the 2010 United States
    Congressional Election might have found that tweets that mentioned
    both the candidate and "Obamacare" were good
    predictors of Republican victories. 2010 was a strong year for
    Republicans, and they ran against Democratic incumbents who'd
    supported President Obama's health care reforms. But health care
    might play a totally different role in the 2012 race, so this
    predictor could be wrong.</p>

    <p class="vt_answer">Finally, there are many more basic issues: political campaigns
    are full of spam and distraction; political speech is full of
    sarcasm, irony, and satire; people who tweet may not be people
    who vote (people over the age of 65 vote regularly but tweet
    rarely; the reverse is true for young people). Computer-based
    linguistic analysis has made enormous strides in understanding
    human language, but many things remain outside its reach.</p>

    <li>How does your method differ from theirs?</li>
    <p class="vt_answer">These papers generally used one of two measures as a proxy for
      electoral success: either counting how many times a candidate
      was mentioned on Twitter during the campaign; or counting how
      many times Twitter users used "positive" or "negative" words to
      describe the candidates.</p> 

    <p class="vt_answer">Our method takes a different tack. We used the results of the 2010
      Congressional election to determine what terms were the best
      predictors of which party won in each Congressional district. We
      are now applying that algorithm to the 2012 election. For more
      information, see the <a href="#algorithms">algorithms</a> section below.</p>
  </ol>
  </div>
  <div id="vt_faq_data">
<h2><a name="data"></a>Data and Sources <span style="font-size:.5em;"><a href="#">Top</a></span></h2>
  <ol>
    <li>Where does the data come from?</li>
    <p class="vt_answer">We mine the data from Twitter using their open <a href="https://dev.twitter.com/docs/api/1/get/search">Search
    API</a>. The Twitter Search API allows anyone to search the
    Twitter feed from the last week or so. </p>
    <li>How do you get the data?</li>
    <p class="vt_answer">We query the Search API every night, for all mentions of each
      Congressional candidate in the past 24 hours. We download and
      store those tweets and related data about when they were created,
      whether they were retweets (RT) or mentions (MT), and other
      metadata.</p> 
    <li>What about candidates with really generic names? Don't you get
      a lot of noise when searching
      for Candidate Smith?</li>

    
    <p class="vt_answer">We've taken steps to try and make sure the data is as clean as
      possible. For instance, when we gathered data on the 2010
      election, we found that one of the candidates shared the same name
      as the kicker for the New Orleans Saints football team. We had a
      lot of data about game outcomes!</p>

    <p class="vt_answer">    This time around, we
      used <a href="http://www.google.com">Google</a> searches identify
      whether similar kinds of situations existed, and made sure to
      clean up the data feed along the way. 
    </p>
    <li>What about spam?</li>
    
    <p class="vt_answer">Spam has become a problem on Twitter lately. We also don't really want to over-rate a candidate simply because their campaign sends out tons of tweets. We already know they think their candidate is great, but that doesn't tell us anything about what voters think.
    </p>
  </ol>
  </div>
  <div id="vt_faq_algorithm">
    <h2><a name="algorithms"></a>Algorithms <span style="font-size:.5em;"><a href="#">Top</a></span></h2>
    <ol>
      <li>How does the algorithm really work?</li>
      <p class="vt_answer">    The algorithm works by mapping the <i>term frequencies</i> of words that appear in tweets about Congressional candidates, to either (1) which party will win the race (Democrats or Republicans); or (2) the vote share that the Democratic candidate will receive. This is a <i>supervised machine learning</i> approach, that uses the results from the last election to train an algorithm for predicting results in the coming one.
      </p>
      <li>How was the algorithm built up?</li>
      
      <p class="vt_answer">During the 2010 Congressional election, we gathered approximately 250,000 tweets about 356 Congressional races. Based on those messages and the election outcomes, we trained two machine learning algorithms to determine what word features of those tweets best predicted whether the Democratic or Republican party candidate won each race.
      </p>
      <p class="vt_answer">We did this a series of steps:</p>
      <ol class="vt_answer">
        <li>Count all of the unique <i>bigrams</i> (pairs of consecutive words) in each tweet</li>
        <li>Count the occurrence of all bigrams in each district for the entire race</li>
        <li><i>Weight</i> the counts so that terms in tweets closer to the election were treated as more important than terms that occurred much earlier in the election</li>
        <li>Build up a matrix, using these counts, of all terms in tweets for both candidates in the race, for all districts. This gave us a matrix of <i>D</i> districts and <i>T</i> terms. With filtering for really common words (like the, is, etc) and really uncommon words this gave us about 1000-2000 unique terms for 356 districts</li>
        <li>Use the <a href="https://github.com/ecpolley/SuperLearner">SuperLearner</a> algorithm to determine which terms were the best predictors (positive or negative) of which party won in each district </li>
      </ol>
      
      <li>Can you go into more detail?</li>
      
      <p class="vt_answer">Sure. This is what's called a <i>bag of words</i> approach: take some text, chop it up into individual terms, count how often each term appears, and use those term:frequency counts as a numerical representation of the message.
      </p>
      
      <p class="vt_answer">In the process, of course, we throw out a ton of information: grammar, sentence structure, sentence context, and so forth. We also usually throw out super-common words like <i>is</i> or <i>won't</i>. But in practice the process often works really well. 
      </p>
      
      <p class="vt_answer">Using these term-frequency representations, we can build up "documents" for each Congressional district: one document is all the messages about either of the two candidates. Because we assume that messages that came out later in the campaign are probably better indicators of who might win than those that came out earlier, we weight them more heavily in the aggregate term counts. 
      </p>
      
      <p class="vt_answer">We can now do real math on this matrix. The <a href="https://github.com/ecpolley/SuperLearner">SuperLearner</a> is what's called an ensemble machine learning algorithm: it takes a bunch of different algorithms (like random forests, support vector machines, lasso regression, and others) and uses each to try and predict the elections on their own. It then combines all of these algorithms together by weighting their individual predictions. In practice, this can result in a synthetic prediction algorithm that's more accurate than the more accurate single algorithm. 
      </p>
      
      <p class="vt_answer">All of this work was done with the <a href="http://r-project.org">R statistical programming
      language</a>. If you are really curious, the code is all
      on <a href="http://github.com/markhuberty/twitter_election2012">Github</a>.</p>

      <li>So how does the finished algorithm actually work?</li>

      <p class="vt_answer">We <i>think</i> the finished algorithm works like this: first, it
      identifies from the language in a candidate's tweets whether
      they are the incumbent or challenger. Since incumbents win
      about 85% of the time, this provides a good baseline. It then
      adjusts the baseline prediction based on sentiment and
      action-related phrases. For instance, "voted hcr" indicating
      that the incumbent voted for health care reform)  was one of
      the most influential predictors alongside incumbency-related
      phrases.</p>
      
      <li>How might it fail?</li>
      <p class="vt_answer">There are a few possible ways this could fail badly:</p>
      <ul class="vt_answer">
        <li>2010 was a strong anti-incumbent year. If 2012 goes
        another way, we may over-predict rates of incumbent
        losses.</li>
        <li>Relevant issues may change. In 2010, the Tea Party,
        health care, and spending were big issues. Those are still
        with us. But we also have new issues like Iran and the Euro
        crisis to deal with.</li>
      </ul>
    </ol>
  </div>

  <div id="faq_vt_topic_models">
    <h2><a href="topic_models"></a>Topic Models <span style="font-size:.5em !important;"><a href="#">Top</a></span></h2>
      <ol>
        <li>What do those <a href="">"topics"</a> mean?</li>
        <p class="vt_answer">    The topics are an attempt to learn from the Twitter stream what topics are most important to each Congressional district. We represent them as the top 5 terms that "best" represent the topic in each district. </p>
        <li>Where do those "topics" come from?</li>
        <p class="vt_answer">    We generate the topics from the same
          term-frequency data that we use for the election
          predictions. <a href="http://en.wikipedia.org/wiki/Topic_model">Topic
            models</a> are a class of machine learning models that try to
          infer similarities among texts by looking at the distribution of words in lots of documents. In our case, those documents are the sets of messages mentioning each candidate, or both candidates in a Congressional district. For a good non-technical summary of topic modeling, see <a href="http://www.cs.princeton.edu/~blei/papers/Blei2012.pdf">this paper</a> by Dave Blei. </p>
        <li>How often are the topics regenerated</li>
        <p class="vt_answer">We generate the topics daily, using the last five days of
          messages for each candidate. If we just used today's messages,
          we might miss candidates or districts with low daily twitter
          volumes. Alternatively, if we used all the data we had,
          eventually the old data would swamp the new and the topics
          would change very little.</p> 
        <li>Do these topics actually mean anything?</li>
        <p class="vt_answer"> Yes and no. Topic models have been very successful in doing things like categorizing magazine articles, tracking how the discussion of different scientific topics changed over time, or even helping to measure and predict <a href="">who votes for what</a> in the US Congress. But they are ultimately just a statistical construct based on the probability that terms occur together often in multiple documents. </p>
      </ol>
</div>

<div id="faq_vt_other">
  <h2><a href="other"></a>Other <span style="font-size:.5em;"><a href="#">Top</a></span></h2>
  <ol>
    <li>Who's this "we"?</li>
    <p class="vt_answer"><a href="http://markhuberty.berkeley.edu">Mark Huberty</a> wrote the original code and paper predicting the 2010 elections. He's the one who's got egg on his face if this all falls flat! <a href="">Len DeGroot</a> built the web front-end and all of the interactive data visualization front-end. <a href="">Hillary Sanders</a> did the background work preparing for the 2012 election, including the thankless task of cross-checking all the names. She also keeps the query jobs running, and generally keeps us all sane.</p>
  </ol>
</div>
</section><!-- /#content -->

</body>
</html>
